# æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜ Transformers ğŸš€

<div align="center">

![æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜Transformers](./imgs/1.png)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2.1+-ee4c2c.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—_Transformers-4.42.4-yellow.svg)](https://github.com/huggingface/transformers)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](LICENSE)

**ç³»ç»ŸåŒ–å­¦ä¹  Hugging Face Transformers çš„å®Œæ•´å®æˆ˜æ•™ç¨‹**

[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [è¯¾ç¨‹å¤§çº²](#-è¯¾ç¨‹å¤§çº²) â€¢ [å­¦ä¹ è·¯çº¿](#-å­¦ä¹ è·¯çº¿) â€¢ [ç¯å¢ƒé…ç½®](#ï¸-ç¯å¢ƒé…ç½®)

</div>

---

## ğŸ“– ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹)
- [é€‚åˆäººç¾¤](#-é€‚åˆäººç¾¤)
- [æ ¸å¿ƒå†…å®¹](#-æ ¸å¿ƒå†…å®¹)
- [é¡¹ç›®ç‰¹è‰²](#-é¡¹ç›®ç‰¹è‰²)
- [è¯¾ç¨‹å¤§çº²](#-è¯¾ç¨‹å¤§çº²)
- [å­¦ä¹ è·¯çº¿](#-å­¦ä¹ è·¯çº¿)
- [ç¯å¢ƒé…ç½®](#ï¸-ç¯å¢ƒé…ç½®)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [é¡¹ç›®ç»Ÿè®¡](#-é¡¹ç›®ç»Ÿè®¡)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)
- [è‡´è°¢](#-è‡´è°¢)

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

æœ¬ä»“åº“æ˜¯ **æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜ Transformers** è¯¾ç¨‹çš„é…å¥—ä»£ç åº“ï¼Œä¸ºå¸Œæœ›ç³»ç»Ÿå­¦ä¹  [Hugging Face Transformers](https://github.com/huggingface/transformers) çš„å¼€å‘è€…ä¸ç ”ç©¶è€…æä¾›å®Œæ•´çš„å­¦ä¹ è·¯å¾„ã€‚

ä»**ç¯å¢ƒæ­å»º**ã€**åŸºç¡€ API** ä½¿ç”¨ï¼Œåˆ° **NLP å¤šä»»åŠ¡å®æˆ˜**ã€**å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰**ã€**ä½ç²¾åº¦/é‡åŒ–è®­ç»ƒ**ï¼Œå†åˆ°**åˆ†å¸ƒå¼è®­ç»ƒ**ï¼Œæ¶µç›–ä»å…¥é—¨åˆ°ç²¾é€šçš„å…¨éƒ¨å†…å®¹ã€‚

---

## ğŸ‘¥ é€‚åˆäººç¾¤

| äººç¾¤ç±»å‹ | åŸºç¡€è¦æ±‚ | å­¦ä¹ ç›®æ ‡ |
|---------|---------|---------|
| ğŸŒ± **åˆå­¦è€…** | Python + åŸºç¡€æ·±åº¦å­¦ä¹  | ä»é›¶æŒæ¡ Transformers ç”¨æ³• |
| ğŸ“ˆ **è¿›é˜¶è€…** | ä¼šç”¨ Pipeline | æ·±å…¥ç†è§£ Tokenizerã€Modelã€Datasetsã€Trainer |
| ğŸ’¼ **å®æˆ˜è€…** | æœ‰é¡¹ç›®éœ€æ±‚ | å®Œæˆæ–‡æœ¬åˆ†ç±»ã€NERã€é—®ç­”ã€æ‘˜è¦ç­‰ä»»åŠ¡è½åœ° |
| ğŸ¤– **å¤§æ¨¡å‹å¼€å‘è€…** | å…³æ³¨å‰æ²¿æŠ€æœ¯ | æŒæ¡ LoRA/QLoRAã€åˆ†å¸ƒå¼è®­ç»ƒã€æ¨¡å‹ä¼˜åŒ– |

---

## ğŸ“š æ ¸å¿ƒå†…å®¹

### ğŸ”° åŸºç¡€ç¯‡
æŒæ¡ **Pipeline**ã€**Tokenizer**ã€**Model**ã€**Datasets**ã€**Evaluate**ã€**Trainer** çš„æ ¸å¿ƒç”¨æ³•ï¼Œé€šè¿‡å®Œæ•´çš„æ–‡æœ¬åˆ†ç±»é¡¹ç›®ä¸²è”çŸ¥è¯†ç‚¹ã€‚

### ğŸ¯ å®æˆ˜ç¯‡
æ¶µç›– 8+ ä¸»æµ NLP ä»»åŠ¡ï¼š
- å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰
- æœºå™¨é˜…è¯»ç†è§£ï¼ˆMRCï¼‰
- å¤šé¡¹é€‰æ‹©ï¼ˆMultiple Choiceï¼‰
- æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆSentence Similarityï¼‰
- æ£€ç´¢å¼/ç”Ÿæˆå¼å¯¹è¯ï¼ˆChatbotï¼‰
- è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰
- æ–‡æœ¬æ‘˜è¦ï¼ˆSummarizationï¼‰

### âš¡ é«˜æ•ˆå¾®è°ƒç¯‡
æ·±å…¥ **PEFT**ï¼ˆParameter-Efficient Fine-Tuningï¼‰æŠ€æœ¯ï¼š
- BitFitã€Prompt Tuningã€P-Tuningã€Prefix Tuning
- **LoRA**ï¼ˆLow-Rank Adaptationï¼‰
- IA3ã€å¤šé€‚é…å™¨ç®¡ç†

### ğŸ”¬ ä½ç²¾åº¦ç¯‡
æŒæ¡æ¨¡å‹é‡åŒ–ä¸åŠ é€Ÿï¼š
- FP16 åŠç²¾åº¦è®­ç»ƒ
- 8-bit é‡åŒ–è®­ç»ƒ
- **4-bit QLoRA** è®­ç»ƒ
- æ”¯æŒ LLaMA2ã€ChatGLM3ã€InternLM ç­‰ä¸»æµå¤§æ¨¡å‹

### ğŸš„ åˆ†å¸ƒå¼ç¯‡
å­¦ä¹ å¤šå¡è®­ç»ƒä¸åŠ é€Ÿï¼š
- Data Parallelï¼ˆDPï¼‰
- Distributed Data Parallelï¼ˆDDPï¼‰
- **Accelerate** æ¡†æ¶
- **Accelerate + DeepSpeed**ï¼ˆZeRO-2/3ï¼‰

---

## âœ¨ é¡¹ç›®ç‰¹è‰²

- âœ… **ç³»ç»ŸåŒ–ç»„ç»‡**ï¼š33 ä¸ªç« èŠ‚æŒ‰éš¾åº¦é€’è¿›ï¼Œç›®å½•ä¸è¯¾ç¨‹ä¸€ä¸€å¯¹åº”
- âœ… **å®æˆ˜å¯¼å‘**ï¼š46 ä¸ª Jupyter Notebooks + 24 ä¸ª Python è„šæœ¬
- âœ… **å¼€ç®±å³ç”¨**ï¼šé…å¤‡å®Œæ•´æ•°æ®é›†å’Œè¯„ä¼°è„šæœ¬ï¼Œå¯ç›´æ¥å¤ç°
- âœ… **å‰æ²¿æŠ€æœ¯**ï¼šæ¶µç›– LoRAã€QLoRAã€DeepSpeed ç­‰æœ€æ–°æ–¹æ³•
- âœ… **ä¸­æ–‡å‹å¥½**ï¼šå…¨ä¸­æ–‡æ–‡æ¡£å’Œæ³¨é‡Šï¼Œé™ä½å­¦ä¹ é—¨æ§›
- âœ… **ä¸»æµç”Ÿæ€**ï¼šç´§è·Ÿ Hugging Face ç¤¾åŒºæœ€ä½³å®è·µ

---

## ğŸ“‹ è¯¾ç¨‹å¤§çº²

### ğŸ“ 01-Getting Startedï¼ˆåŸºç¡€å…¥é—¨ï¼‰

| ç« èŠ‚ | å†…å®¹ | æ ¸å¿ƒçŸ¥è¯†ç‚¹ |
|-----|------|-----------|
| 01 | Introduction | ç¯å¢ƒé…ç½®ã€å¿«é€Ÿå…¥é—¨ |
| 02 | Pipeline | é«˜å±‚ API ä½¿ç”¨ |
| 03 | Tokenizer | æ–‡æœ¬é¢„å¤„ç†ä¸ç¼–ç  |
| 04 | Model | æ¨¡å‹åŠ è½½ä¸æ¨ç†ï¼ˆå«æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹ï¼‰ |
| 05 | Datasets | æ•°æ®é›†åŠ è½½ä¸å¤„ç† |
| 06 | Evaluate | æ¨¡å‹è¯„ä¼°ä¸æŒ‡æ ‡ |
| 07 | Trainer | è®­ç»ƒå¾ªç¯å°è£… |

### ğŸ¯ 02-NLP Tasksï¼ˆå®æˆ˜ä»»åŠ¡ï¼‰

| ç« èŠ‚ | ä»»åŠ¡ç±»å‹ | åº”ç”¨åœºæ™¯ |
|-----|---------|---------|
| 08 | Transformers Solution | è§£å†³æ–¹æ¡ˆæ€»è§ˆ |
| 09 | Token Classification | å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ |
| 10 | Question Answering | æœºå™¨é˜…è¯»ç†è§£ï¼ˆå«æ»‘åŠ¨çª—å£ï¼‰ |
| 11 | Multiple Choice | å¤šé¡¹é€‰æ‹©ï¼ˆC3 æ•°æ®é›†ï¼‰ |
| 12 | Sentence Similarity | æ–‡æœ¬ç›¸ä¼¼åº¦åŒ¹é… |
| 13 | Retrieval Chatbot | æ£€ç´¢å¼å¯¹è¯ï¼ˆFAQï¼‰ |
| 14 | Language Model | å› æœ/æ©ç è¯­è¨€æ¨¡å‹ |
| 15 | Text Summarization | æ–‡æœ¬æ‘˜è¦ï¼ˆT5/GLMï¼‰ |
| 16 | Generative Chatbot | ç”Ÿæˆå¼å¯¹è¯ï¼ˆAlpaca æ ¼å¼ï¼‰ |

### âš¡ 03-PEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰

| ç« èŠ‚ | æ–¹æ³• | ç‰¹ç‚¹ |
|-----|------|------|
| 17 | BitFit | ä»…å¾®è°ƒåç½®é¡¹ |
| 18 | Prompt Tuning | è½¯æç¤ºå­¦ä¹  |
| 19 | P-Tuning | è¿ç»­æç¤ºä¼˜åŒ– |
| 20 | Prefix Tuning | å‰ç¼€è°ƒä¼˜ |
| 21 | LoRA | ä½ç§©é€‚é…ï¼ˆâ­ æ¨èï¼‰ |
| 22 | IA3 | æ¿€æ´»å€¼ç¼©æ”¾ |
| 23 | PEFT Advanced | å¤šé€‚é…å™¨ç®¡ç† |

### ğŸ”¬ 04-Kbit Trainingï¼ˆé‡åŒ–è®­ç»ƒï¼‰

| ç« èŠ‚ | ç²¾åº¦ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| 24 | LLM Download | å¤§æ¨¡å‹ä¸‹è½½ä¸åŠ è½½ |
| 25 | 16-bit Training | FP16 åŠç²¾åº¦ï¼ˆLLaMA2ã€ChatGLM3ï¼‰ |
| 26 | 8-bit Training | INT8 é‡åŒ–è®­ç»ƒ |
| 27 | 4-bit Training | QLoRA 4-bitï¼ˆå«æƒé‡å¯è§†åŒ–ï¼‰ |

### ğŸš„ 05-Distributed Trainingï¼ˆåˆ†å¸ƒå¼è®­ç»ƒï¼‰

| ç« èŠ‚ | æŠ€æœ¯ | åº”ç”¨ |
|-----|------|------|
| 28 | Remote SSH | è¿œç¨‹è®­ç»ƒä¸ DP |
| 29 | Data Parallel | æ•°æ®å¹¶è¡Œ |
| 30 | DDP | åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ |
| 31 | Accelerate DDP | Accelerate å°è£… |
| 32 | Accelerate Advanced | é«˜çº§é…ç½® |
| 33 | Accelerate + DeepSpeed | ZeRO-2/3 ä¼˜åŒ– |

### ğŸ”§ Othersï¼ˆè¡¥å……æŠ€èƒ½ï¼‰

- **Optuna è¶…å‚æ•°æœç´¢**ï¼šè‡ªåŠ¨åŒ–è°ƒå‚

---

## ğŸ—ºï¸ å­¦ä¹ è·¯çº¿

```mermaid
graph TD
    A[å¼€å§‹å­¦ä¹ ] --> B[01-Getting Started<br/>åŸºç¡€å…¥é—¨]
    B --> C{é€‰æ‹©æ–¹å‘}
    C -->|ä»»åŠ¡å®æˆ˜| D[02-NLP Tasks<br/>é€‰æ‹©æ„Ÿå…´è¶£çš„ä»»åŠ¡]
    C -->|æ¨¡å‹ä¼˜åŒ–| E[03-PEFT<br/>é«˜æ•ˆå¾®è°ƒ]
    D --> E
    E --> F[04-Kbit Training<br/>é‡åŒ–è®­ç»ƒ]
    F --> G[05-Distributed Training<br/>åˆ†å¸ƒå¼è®­ç»ƒ]
    G --> H[Others<br/>è¶…å‚æœç´¢ç­‰]
    H --> I[å®Œæˆå­¦ä¹  ğŸ‰]
    
    style A fill:#e1f5e1
    style B fill:#fff4e1
    style D fill:#e1f0ff
    style E fill:#ffe1f0
    style F fill:#f0e1ff
    style G fill:#e1ffe1
    style I fill:#ffd1d1
```

### ğŸ“ å­¦ä¹ å»ºè®®

1. **ç¬¬ä¸€é˜¶æ®µ**ï¼ˆ1-2 å‘¨ï¼‰ï¼šå®Œæˆ `01-Getting Started` å…¨éƒ¨ 7 ä¸ªç« èŠ‚ï¼Œæ‰“ç‰¢åŸºç¡€
2. **ç¬¬äºŒé˜¶æ®µ**ï¼ˆ2-3 å‘¨ï¼‰ï¼šä» `02-NLP Tasks` ä¸­é€‰æ‹© 2-3 ä¸ªæ„Ÿå…´è¶£çš„ä»»åŠ¡æ·±å…¥å®æˆ˜
3. **ç¬¬ä¸‰é˜¶æ®µ**ï¼ˆ1-2 å‘¨ï¼‰ï¼šå­¦ä¹  `03-PEFT`ï¼ŒæŒæ¡ LoRA ç­‰é«˜æ•ˆå¾®è°ƒæ–¹æ³•
4. **ç¬¬å››é˜¶æ®µ**ï¼ˆ1 å‘¨ï¼‰ï¼šäº†è§£ `04-Kbit Training`ï¼Œå­¦ä¹ æ¨¡å‹é‡åŒ–
5. **ç¬¬äº”é˜¶æ®µ**ï¼ˆ1-2 å‘¨ï¼‰ï¼šå­¦ä¹  `05-Distributed Training`ï¼ŒæŒæ¡å¤šå¡è®­ç»ƒ
6. **è¿›é˜¶**ï¼šæ ¹æ®éœ€è¦å­¦ä¹  `Others` ä¸­çš„è¶…å‚æœç´¢ç­‰æŠ€èƒ½

---

## ğŸ› ï¸ ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- **Python**ï¼š3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **CUDA**ï¼š11.8 æˆ–æ›´é«˜ï¼ˆGPU è®­ç»ƒéœ€è¦ï¼‰
- **å†…å­˜**ï¼šå»ºè®® 16GB+
- **æ˜¾å­˜**ï¼šå»ºè®® 8GB+ï¼ˆé‡åŒ–è®­ç»ƒå¯é™ä½è¦æ±‚ï¼‰

### æ ¸å¿ƒä¾èµ–

| ä¾èµ–åº“ | æ¨èç‰ˆæœ¬ | è¯´æ˜ |
|--------|---------|------|
| `torch` | 2.2.1+cu118 | æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆéœ€åŒ¹é… CUDA ç‰ˆæœ¬ï¼‰ |
| `transformers` | 4.42.4 | Hugging Face æ ¸å¿ƒåº“ |
| `peft` | 0.11.1 | å‚æ•°é«˜æ•ˆå¾®è°ƒ |
| `datasets` | 2.20.0 | æ•°æ®é›†åŠ è½½ |
| `accelerate` | 0.32.1 | åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿ |
| `bitsandbytes` | 0.43.1 | é‡åŒ–è®­ç»ƒï¼ˆä½ç²¾åº¦ç« èŠ‚éœ€è¦ï¼‰ |
| `faiss-cpu` | 1.7.4 | å‘é‡æ£€ç´¢ï¼ˆæ£€ç´¢å¼å¯¹è¯éœ€è¦ï¼‰ |
| `tensorboard` | 2.14.0 | è®­ç»ƒå¯è§†åŒ– |

### å®‰è£…æ­¥éª¤

```bash
# 1. å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch transformers peft datasets accelerate

# 2. å®‰è£…é‡åŒ–è®­ç»ƒä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install bitsandbytes

# 3. å®‰è£…å…¶ä»–å·¥å…·ï¼ˆå¯é€‰ï¼‰
pip install faiss-cpu tensorboard

# 4. éªŒè¯å®‰è£…
python -c "import torch; import transformers; print(f'PyTorch: {torch.__version__}, Transformers: {transformers.__version__}')"
```

### å›½å†…é•œåƒåŠ é€Ÿï¼ˆå¯é€‰ï¼‰

```bash
# ä½¿ç”¨æ¸…åé•œåƒ
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch transformers peft datasets accelerate

# è®¾ç½® Hugging Face é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ å…‹éš†ä»“åº“

```bash
git clone https://github.com/<your-org>/learn-huggingface.git
cd learn-huggingface
```

### 2ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
pip install torch transformers peft datasets accelerate
```

### 3ï¸âƒ£ è¿è¡Œç¬¬ä¸€ä¸ªç¤ºä¾‹

```bash
cd "01-Getting Started/01-introduction"
jupyter notebook demo.ipynb
```

æˆ–ç›´æ¥è¿è¡Œ Python è„šæœ¬ï¼š

```bash
python demo.py
```

### 4ï¸âƒ£ å°è¯•å®Œæ•´ä»»åŠ¡

**æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹**ï¼š
```bash
cd "01-Getting Started/04-model"
jupyter notebook classification_demo.ipynb
```

**å‘½åå®ä½“è¯†åˆ«ç¤ºä¾‹**ï¼š
```bash
cd "02-NLP Tasks/09-token_classification"
jupyter notebook ner_demo.ipynb
```

---

## ğŸ“Š é¡¹ç›®ç»Ÿè®¡

- ğŸ“‚ **æ€»ç« èŠ‚æ•°**ï¼š33 ä¸ª
- ğŸ““ **Jupyter Notebooks**ï¼š46 ä¸ª
- ğŸ **Python è„šæœ¬**ï¼š24 ä¸ª
- ğŸ“¦ **é¡¹ç›®å¤§å°**ï¼šçº¦ 226 MB
- ğŸ¯ **è¦†ç›–ä»»åŠ¡**ï¼š8+ ä¸»æµ NLP ä»»åŠ¡
- âš¡ **PEFT æ–¹æ³•**ï¼š6+ ç§é«˜æ•ˆå¾®è°ƒæŠ€æœ¯

---

## â“ å¸¸è§é—®é¢˜

<details>
<summary><b>Q1: éœ€è¦ GPU å—ï¼Ÿ</b></summary>

- **åŸºç¡€ç¯‡**ï¼ˆ01-Getting Startedï¼‰ï¼šCPU å³å¯è¿è¡Œ
- **å®æˆ˜ç¯‡**ï¼ˆ02-NLP Tasksï¼‰ï¼šå»ºè®®ä½¿ç”¨ GPUï¼Œä½†å°æ¨¡å‹å¯ç”¨ CPU
- **PEFT/é‡åŒ–/åˆ†å¸ƒå¼**ï¼šå¼ºçƒˆå»ºè®®ä½¿ç”¨ GPUï¼Œé‡åŒ–è®­ç»ƒå¯é™ä½æ˜¾å­˜éœ€æ±‚
</details>

<details>
<summary><b>Q2: å¦‚ä½•ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†ï¼Ÿ</b></summary>

- å¤§éƒ¨åˆ†ç¤ºä¾‹ä¼šè‡ªåŠ¨ä» Hugging Face Hub ä¸‹è½½
- å›½å†…ç”¨æˆ·å»ºè®®è®¾ç½®é•œåƒï¼š`export HF_ENDPOINT=https://hf-mirror.com`
- ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½åæ”¾åˆ°æœ¬åœ°è·¯å¾„
</details>

<details>
<summary><b>Q3: é‡åˆ° CUDA ç‰ˆæœ¬ä¸åŒ¹é…æ€ä¹ˆåŠï¼Ÿ</b></summary>

```bash
# æŸ¥çœ‹ CUDA ç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorchï¼ˆä»¥ CUDA 11.8 ä¸ºä¾‹ï¼‰
pip install torch==2.2.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html
```
</details>

<details>
<summary><b>Q4: å¯ä»¥åªå­¦ä¹ éƒ¨åˆ†ç« èŠ‚å—ï¼Ÿ</b></summary>

å¯ä»¥ï¼å»ºè®®å…ˆå®Œæˆ `01-Getting Started` æ‰“åŸºç¡€ï¼Œç„¶åæ ¹æ®éœ€æ±‚é€‰æ‹©æ„Ÿå…´è¶£çš„ç« èŠ‚å­¦ä¹ ã€‚
</details>

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€ä¿®å¤ Bugã€å®Œå–„æ–‡æ¡£ï¼

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/your-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -m 'Add some feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/your-feature`
5. æäº¤ Pull Request

---

## ğŸ™ è‡´è°¢

æœ¬ä»“åº“é…å¥— **æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜ Transformers** ç³»åˆ—è¯¾ç¨‹ï¼Œè§†é¢‘ä¸ä»£ç æŒç»­æ›´æ–°ä¸­ã€‚

- æ„Ÿè°¢ [Hugging Face](https://huggingface.co/) æä¾›ä¼˜ç§€çš„å¼€æºç”Ÿæ€
- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œå­¦ä¹ è€…çš„æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ [Issue](https://github.com/<your-org>/learn-huggingface/issues) åé¦ˆã€‚

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Star æ”¯æŒä¸€ä¸‹ï¼â­**

Made with â¤ï¸ by Transformers å­¦ä¹ è€…

</div>
